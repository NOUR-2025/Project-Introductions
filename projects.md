# Project Overviews
***

## Saung Oo

**Title:** Air Quality Control Monitor in Hazelwood

**Summary:**

***

## Daphne Griffin

**Title:**

**Summary:**

***

## Yang Ye

**Title: Enhancing Robotic Instruction Understanding through Multimodal Human Cues**

**Summary: This project investigates how integrating human gaze (eye-tracking) and manual gestures with spoken language instructions can improve a robot’s ability to understand and execute commands. By analyzing multimodal inputs—eye movement, hand movement, and verbal utterances—the system aims to bridge the gap between natural human communication and machine interpretation, paving the way for more intuitive and accurate human-robot interaction.**

***

## Sean Jacobs

**Title:**

**Summary:**

***

## John Onubogu

**Title:**

**Summary:**

***

## Aishwarya Krishnamoorthy

**Title:**

**Summary:**

***

## Yifei Tian

**Title:**

**Summary:**

***

## Zhenyu Wu

**Title:**

**Summary:**

***

## Yifan Jing

**Title:**

**Summary:**

***

## Ethan Crosby

**Title:**

**Summary:**

***

## Alejandro Ciuba

**Title:** Langauge communities and the field of low-resource NLP

**Summary:** This work is a literature survey exploring how the natural-language processing (NLP) research field currently works with speakers of low-resource languages. Low-resource languages are those where NLP systems (e.g., machine translation, speech-to-text, autocomplete, datasets) are sparsely available. Addtionally, human-computer interaction (HCI) has been focusing more on community-focused engagement. This work examines in what ways do NLP researchers interact with speakers from these communities and discusses how HCI scholarship can help NLP foster better community relations.
